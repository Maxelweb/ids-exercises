{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to Data Science 2021\n",
    "\n",
    "# Week 6: Recap"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 1 | Linear regression with feature selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download the [TED Talks](https://www.kaggle.com/rounakbanik/ted-talks) dataset from Kaggle. Your task is to predict both the ratings and the number of views of a given TED talk. You should focus only on the <span style=\"background-color: #ccfff2\">ted_main</span> table.\n",
    "\n",
    "1. Download the data, extract the following ratings from column <span style=\"background-color: #ccfff2\">ratings</span>: <span style=\"background-color: #ccfff2\">Funny</span>, <span style=\"background-color: #ccfff2\">Confusing</span>, <span style=\"background-color: #ccfff2\">Inspiring</span>. Store these values into respective columns so that they are easier to access. Next, extract the tags from column <span style=\"background-color: #ccfff2\">tags</span>. Count the number of occurrences of each tag and select the top-100 most common tags. Create a binary variable for each of these and include them in your data table, so that you can directly see whether a given tag (among the top-100 tags) is used in a given TED talk or not."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "\n",
    "ted_main = pd.read_csv('./ted_main.csv', sep=',')\n",
    "ted_main['ratings'] = ted_main.ratings.apply(lambda x: ast.literal_eval(x))\n",
    "ted_main['Funny'] = ted_main.ratings.apply(lambda x: list(y['count'] for y in x if y['name']=='Funny')[0])\n",
    "ted_main['Confusing'] = ted_main.ratings.apply(lambda x: list(y['count'] for y in x if y['name']=='Confusing')[0])\n",
    "ted_main['Inspiring'] = ted_main.ratings.apply(lambda x: list(y['count'] for y in x if y['name']=='Inspiring')[0])\n",
    "\n",
    "tags = ted_main.tags.apply(lambda x: ast.literal_eval(x))\n",
    "tags = tags.apply(pd.Series).stack().reset_index(drop=True)\n",
    "tags = pd.DataFrame(tags)\n",
    "tags = tags.rename(columns={0: 'Tag'})\n",
    "tags['count'] = tags.groupby('Tag')['Tag'].transform('count')\n",
    "tags = tags.sort_values('count', ascending=False).drop_duplicates().head(100)['Tag']\n",
    "\n",
    "for t in tags:\n",
    "    ted_main[t] = ted_main.tags.apply(lambda x: (0 if t not in ast.literal_eval(x) else 1))\n",
    "\n",
    "ted_main"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_129374/4202321289.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ted_main[t] = ted_main.tags.apply(lambda x: (0 if t not in ast.literal_eval(x) else 1))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>film_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>num_speaker</th>\n",
       "      <th>published_date</th>\n",
       "      <th>...</th>\n",
       "      <th>food</th>\n",
       "      <th>religion</th>\n",
       "      <th>family</th>\n",
       "      <th>ecology</th>\n",
       "      <th>peace</th>\n",
       "      <th>poetry</th>\n",
       "      <th>demo</th>\n",
       "      <th>illness</th>\n",
       "      <th>universe</th>\n",
       "      <th>energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4553</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>60</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>265</td>\n",
       "      <td>With the same humor and humanity he exuded in ...</td>\n",
       "      <td>977</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>43</td>\n",
       "      <td>Al Gore</td>\n",
       "      <td>Al Gore: Averting the climate crisis</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124</td>\n",
       "      <td>New York Times columnist David Pogue takes aim...</td>\n",
       "      <td>1286</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140739200</td>\n",
       "      <td>26</td>\n",
       "      <td>David Pogue</td>\n",
       "      <td>David Pogue: Simplicity sells</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>In an emotionally charged talk, MacArthur-winn...</td>\n",
       "      <td>1116</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140912000</td>\n",
       "      <td>35</td>\n",
       "      <td>Majora Carter</td>\n",
       "      <td>Majora Carter: Greening the ghetto</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>You've never seen data presented like this. Wi...</td>\n",
       "      <td>1190</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140566400</td>\n",
       "      <td>48</td>\n",
       "      <td>Hans Rosling</td>\n",
       "      <td>Hans Rosling: The best stats you've ever seen</td>\n",
       "      <td>1</td>\n",
       "      <td>1151440680</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>17</td>\n",
       "      <td>Between 2008 and 2016, the United States depor...</td>\n",
       "      <td>476</td>\n",
       "      <td>TED2017</td>\n",
       "      <td>1496707200</td>\n",
       "      <td>4</td>\n",
       "      <td>Duarte Geraldino</td>\n",
       "      <td>Duarte Geraldino: What we're missing in the de...</td>\n",
       "      <td>1</td>\n",
       "      <td>1505851216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>6</td>\n",
       "      <td>How can you study Mars without a spaceship? He...</td>\n",
       "      <td>290</td>\n",
       "      <td>TED2017</td>\n",
       "      <td>1492992000</td>\n",
       "      <td>3</td>\n",
       "      <td>Armando Azua-Bustos</td>\n",
       "      <td>Armando Azua-Bustos: The most Martian place on...</td>\n",
       "      <td>1</td>\n",
       "      <td>1505919737</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>10</td>\n",
       "      <td>Science fiction visions of the future show us ...</td>\n",
       "      <td>651</td>\n",
       "      <td>TED2017</td>\n",
       "      <td>1492992000</td>\n",
       "      <td>1</td>\n",
       "      <td>Radhika Nagpal</td>\n",
       "      <td>Radhika Nagpal: What intelligent machines can ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1506006095</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>32</td>\n",
       "      <td>In an unmissable talk about race and politics ...</td>\n",
       "      <td>1100</td>\n",
       "      <td>TEDxMileHigh</td>\n",
       "      <td>1499472000</td>\n",
       "      <td>1</td>\n",
       "      <td>Theo E.J. Wilson</td>\n",
       "      <td>Theo E.J. Wilson: A black man goes undercover ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1506024042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>8</td>\n",
       "      <td>With more than half of the world population li...</td>\n",
       "      <td>519</td>\n",
       "      <td>TED2017</td>\n",
       "      <td>1492992000</td>\n",
       "      <td>1</td>\n",
       "      <td>Karoliina Korppoo</td>\n",
       "      <td>Karoliina Korppoo: How a video game might help...</td>\n",
       "      <td>1</td>\n",
       "      <td>1506092422</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2550 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comments                                        description  duration  \\\n",
       "0         4553  Sir Ken Robinson makes an entertaining and pro...      1164   \n",
       "1          265  With the same humor and humanity he exuded in ...       977   \n",
       "2          124  New York Times columnist David Pogue takes aim...      1286   \n",
       "3          200  In an emotionally charged talk, MacArthur-winn...      1116   \n",
       "4          593  You've never seen data presented like this. Wi...      1190   \n",
       "...        ...                                                ...       ...   \n",
       "2545        17  Between 2008 and 2016, the United States depor...       476   \n",
       "2546         6  How can you study Mars without a spaceship? He...       290   \n",
       "2547        10  Science fiction visions of the future show us ...       651   \n",
       "2548        32  In an unmissable talk about race and politics ...      1100   \n",
       "2549         8  With more than half of the world population li...       519   \n",
       "\n",
       "             event   film_date  languages         main_speaker  \\\n",
       "0          TED2006  1140825600         60         Ken Robinson   \n",
       "1          TED2006  1140825600         43              Al Gore   \n",
       "2          TED2006  1140739200         26          David Pogue   \n",
       "3          TED2006  1140912000         35        Majora Carter   \n",
       "4          TED2006  1140566400         48         Hans Rosling   \n",
       "...            ...         ...        ...                  ...   \n",
       "2545       TED2017  1496707200          4     Duarte Geraldino   \n",
       "2546       TED2017  1492992000          3  Armando Azua-Bustos   \n",
       "2547       TED2017  1492992000          1       Radhika Nagpal   \n",
       "2548  TEDxMileHigh  1499472000          1     Theo E.J. Wilson   \n",
       "2549       TED2017  1492992000          1    Karoliina Korppoo   \n",
       "\n",
       "                                                   name  num_speaker  \\\n",
       "0             Ken Robinson: Do schools kill creativity?            1   \n",
       "1                  Al Gore: Averting the climate crisis            1   \n",
       "2                         David Pogue: Simplicity sells            1   \n",
       "3                    Majora Carter: Greening the ghetto            1   \n",
       "4         Hans Rosling: The best stats you've ever seen            1   \n",
       "...                                                 ...          ...   \n",
       "2545  Duarte Geraldino: What we're missing in the de...            1   \n",
       "2546  Armando Azua-Bustos: The most Martian place on...            1   \n",
       "2547  Radhika Nagpal: What intelligent machines can ...            1   \n",
       "2548  Theo E.J. Wilson: A black man goes undercover ...            1   \n",
       "2549  Karoliina Korppoo: How a video game might help...            1   \n",
       "\n",
       "      published_date  ... food religion family ecology peace poetry  demo  \\\n",
       "0         1151367060  ...    0        0      0       0     0      0     0   \n",
       "1         1151367060  ...    0        0      0       0     0      0     0   \n",
       "2         1151367060  ...    0        0      0       0     0      0     0   \n",
       "3         1151367060  ...    0        0      0       0     0      0     0   \n",
       "4         1151440680  ...    0        0      0       0     0      0     1   \n",
       "...              ...  ...  ...      ...    ...     ...   ...    ...   ...   \n",
       "2545      1505851216  ...    0        0      1       0     0      0     0   \n",
       "2546      1505919737  ...    0        0      0       0     0      0     0   \n",
       "2547      1506006095  ...    0        0      0       0     0      0     0   \n",
       "2548      1506024042  ...    0        0      0       0     0      0     0   \n",
       "2549      1506092422  ...    0        0      0       0     0      0     0   \n",
       "\n",
       "      illness  universe  energy  \n",
       "0           0         0       0  \n",
       "1           0         0       0  \n",
       "2           0         0       0  \n",
       "3           0         0       0  \n",
       "4           0         0       0  \n",
       "...       ...       ...     ...  \n",
       "2545        0         0       0  \n",
       "2546        0         1       0  \n",
       "2547        0         0       0  \n",
       "2548        0         0       0  \n",
       "2549        0         0       0  \n",
       "\n",
       "[2550 rows x 120 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Construct a linear regression model to predict the number of views based on the data in the <span style=\"background-color: #ccfff2\">ted_main</span> table, including the binary variables for the top-100 tags that you just created. You can ignore the speaker name and other non-structured data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "pred_cols = tags.append(pd.Series('comments')).append(pd.Series('duration')).append(pd.Series('num_speaker'))\n",
    "\n",
    "X = np.array(ted_main[pred_cols].values.tolist())\n",
    "y = np.array(ted_main['views'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, shuffle=True, random_state=12)\n",
    "\n",
    "reg = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "reg.score(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5093293920341078"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Do the same for the <span style=\"background-color: #ccfff2\">Funny</span>, <span style=\"background-color: #ccfff2\">Confusing</span>, and <span style=\"background-color: #ccfff2\">Inspiring</span> ratings."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "pred_cols1 = ['Funny', 'Confusing', 'Inspiring']\n",
    "X1 = np.array(ted_main[pred_cols1].values.tolist())\n",
    "X1_train, X1_test, y1_train, y1_test = tts(X1, y, test_size=0.2, shuffle=True, random_state=12)\n",
    "\n",
    "reg_tags = LinearRegression().fit(X1_train,y1_train)\n",
    "\n",
    "reg_tags.score(X1_test, y1_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7487263670624724"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. You will probably notice that most of the tags are not useful in predicting the views and the ratings. You should use some kind of variable selection to prune the set of tags that are included in the model. You can use for example classical p-values or more modern [LASSO](https://en.wikipedia.org/wiki/Lasso_(statistics)) techniques. Which tags are the best predictors of each of the response variables?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso_reg = LassoCV(eps=1e-3, normalize=True).fit(X_train, y_train)\n",
    "\n",
    "lasso_reg.score(X_test, y_test)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.519049671654138"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Produce summaries of your results. Could you recommend good tags – or tags to avoid! – for speakers targeting plenty of views and/or certain ratings?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Remember to submit your code on Moodle. You can return this Jupyter notebook (.ipynb) or .py, .R, etc depending on your programming preferences.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 2 | Symbol classification (part 2)\n",
    "\n",
    "Note that it is strongly recommended to use Python in this exercise. However, if you can find a suitable AutoML implementation for your favorite language (e.g [here](http://h2o-release.s3.amazonaws.com/h2o/master/3888/docs-website/h2o-docs/automl.html) seems to be one for R) then you are free to use that language as well.\n",
    "\n",
    "Use the preprocessed data from week 3 (you can also produce them using the example solutions of week 3)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. This time train a *random forest classifier* on the data. A random forest is a collection of *decision trees*, which makes it an *ensemble* of classifiers. Each tree uses a random subset of the features to make it’s prediction. Without tuning any parameters, how is the accuracy?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# OLD CODE TO LOAD DATA\n",
    "labels = pd.read_csv('./hasyv2/hasy-data-labels.csv', sep=',')\n",
    "labels = labels[labels['symbol_id'] >= 70]\n",
    "labels = labels[labels['symbol_id'] <= 80]\n",
    "paths = labels['path']\n",
    "labels = labels['latex']\n",
    "images = np.array([np.array(cv2.cvtColor(cv2.imread('hasyv2/'+file),cv2.COLOR_BGR2GRAY)).reshape(-1) for file in paths])\n",
    "X_train, X_test, y_train, y_test = tts(images, labels, test_size=0.2, shuffle=True, random_state=12)\n",
    "\n",
    "# ACTUAL CODE\n",
    "clf = RandomForestClassifier().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8431372549019608"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. The amount of trees to use as a part of the random forest is an example of a hyperparameter, because it is a parameter that is set prior to the learning process. In contrast, a parameter is a value in the model that is learned from the data. Train 20 classifiers, with varying amounts of decision trees starting from 10 up until 200, and plot the test accuracy as a function of the amount of classifiers. Does the accuracy keep increasing? Is more better?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cl = []\n",
    "for i in range(1,21):\n",
    "    cl.append(RandomForestClassifier(n_estimators=i*10).fit(X_train, y_train))\n",
    "\n",
    "Xgr = []\n",
    "Ygr = []\n",
    "\n",
    "for i in range(1,21):\n",
    "    Xgr.append(i*10)\n",
    "    Ygr.append(cl[i-1].score(X_test, y_test))\n",
    "\n",
    "plt.plot(Xgr, Ygr)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. If we had picked the amount of decision trees by taking the value with the best test accuracy from the last plot, we would have *overfit* our hyperparameters to the test data. Can you see why it is a mistake to tune hyperparameters of your model by using the test data?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "I think that tuning the model to fit more the test data is wrong in principle, because the test data partition is pretty smaller than the training one. We then would have a high accuracy score, since it's supposed to be exactly like this, but the model is overfitted on THAT test data; if, for instance, we reshuffle test and training data, then the model would perform totally worse."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Reshuffle and resplit the data so that it is divided in 3 parts: training (80%), validation (10%) and test (10%). Repeatedly train a model of your choosing (e.g random forest) on the training data, and evaluate it’s performance on the validation set, while tuning the hyperparameters so that the accuracy on the validation set increases. Then, finally evaluate the performance of your model on the test data. What can you say in terms of the generalization of your model?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from sklearn.utils import shuffle\n",
    "images, labels = shuffle(images, labels, random_state=15)\n",
    "\n",
    "X, X_test, y, y_test = tts(images, labels, train_size=0.8, shuffle=True, random_state=12)\n",
    "X_train, X_validate, y_train, y_validate = tts(X, y, test_size=0.25)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, min_samples_split=2, max_features=0.25).fit(X_train, y_train)\n",
    "\n",
    "display(clf.score(X_validate, y_validate), clf.score(X_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0.8235294117647058"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. This process of picking a suitable model, evaluating its performance and tuning the hyperparameters is very time consuming. A new idea in machine learning is the concept of automating this by using an optimization algorithm to find the best model in the space of models and their hyperparameters. Have a look at [TPOT](https://github.com/EpistasisLab/tpot), an automated ML solution that finds a good model and a good set of hyperparameters automatically. Try it on this data, it should outperform simple models like the ones we tried easily. Note that running the algorithm might take a while, depending on the strength of your computer. \n",
    "\n",
    "*Note*: In case it is running for too long, try checking if the parameters you are using when calling TPOT are reasonable, i.e. try reducing number of ‘generations’ or ‘population_size’. TPOT uses cross-validation internally, so we don’t need our own validation set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "tpot = TPOTClassifier(generations=3, population_size=20, verbosity=2, random_state=42)\n",
    "tpot.fit(X_train, y_train)\n",
    "tpot.score(X_test, y_test)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8545381847261095\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.8545381847261095\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.8545515127282421\n",
      "\n",
      "Best pipeline: LogisticRegression(ExtraTreesClassifier(input_matrix, bootstrap=True, criterion=gini, max_features=0.7500000000000001, min_samples_leaf=16, min_samples_split=8, n_estimators=100), C=5.0, dual=False, penalty=l2)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Remember to submit your code on Moodle. You can return this Jupyter notebook (.ipynb) or .py, .R, etc depending on your programming preferences.**"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "4e1d9a8909477db77738c33245c29c7265277ef753467dede8cf3f814cde494e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}