{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction to Data Science 2021\n",
    "\n",
    "# Week 1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 1 | Matrix warm-up\n",
    "<span style=\"background-color: #ccfff2\"> *Note: You can find tutorials for NumPy and Pandas under 'Useful tutorials' in Moodle.*</span>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "One of the most useful properties of any scientific programming language (Python with NumPy, R, Julia, etc) is that they allow us to work with matrices efficiently. Let's learn more about these features!\n",
    "\n",
    "### 1.1 Basics\n",
    "\n",
    "1. Let's start by creating two arrays <span style=\"background-color: #ccfff2\"> A</span> and <span style=\"background-color: #ccfff2\"> B</span> which each have the integers <span style=\"background-color: #ccfff2\"> 0, 1, 2, ..., 1e7-1</span>. Use the normal arrays or lists of the programming language you are using, e.g. *list* or *[ ]* in Python."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "A = B = [i for i in range(0,int(1e7-1))]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Create a function that uses a <span style=\"background-color: #ccfff2\"> for loop</span> or equivalent to return a new array <span style=\"background-color: #ccfff2\"> C</span>, which contains the <span style=\"background-color: #ccfff2\"> element-wise sum of *A* and *B*</span>, e.g. C should contain the integers <span style=\"background-color: #ccfff2\"> 0, 2, 4, etc</span>."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def add_with_for(A,B):\n",
    "    C = []\n",
    "    for i in range(len(A)):\n",
    "        C.append(A[i]+B[i])\n",
    "    return C\n",
    "\n",
    "add_with_for(A,B)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 14,\n",
       " 16,\n",
       " 18,\n",
       " 20,\n",
       " 22,\n",
       " 24,\n",
       " 26,\n",
       " 28,\n",
       " 30,\n",
       " 32,\n",
       " 34,\n",
       " 36,\n",
       " 38,\n",
       " 40,\n",
       " 42,\n",
       " 44,\n",
       " 46,\n",
       " 48,\n",
       " 50,\n",
       " 52,\n",
       " 54,\n",
       " 56,\n",
       " 58,\n",
       " 60,\n",
       " 62,\n",
       " 64,\n",
       " 66,\n",
       " 68,\n",
       " 70,\n",
       " 72,\n",
       " 74,\n",
       " 76,\n",
       " 78,\n",
       " 80,\n",
       " 82,\n",
       " 84,\n",
       " 86,\n",
       " 88,\n",
       " 90,\n",
       " 92,\n",
       " 94,\n",
       " 96,\n",
       " 98,\n",
       " 100,\n",
       " 102,\n",
       " 104,\n",
       " 106,\n",
       " 108,\n",
       " 110,\n",
       " 112,\n",
       " 114,\n",
       " 116,\n",
       " 118,\n",
       " 120,\n",
       " 122,\n",
       " 124,\n",
       " 126,\n",
       " 128,\n",
       " 130,\n",
       " 132,\n",
       " 134,\n",
       " 136,\n",
       " 138,\n",
       " 140,\n",
       " 142,\n",
       " 144,\n",
       " 146,\n",
       " 148,\n",
       " 150,\n",
       " 152,\n",
       " 154,\n",
       " 156,\n",
       " 158,\n",
       " 160,\n",
       " 162,\n",
       " 164,\n",
       " 166,\n",
       " 168,\n",
       " 170,\n",
       " 172,\n",
       " 174,\n",
       " 176,\n",
       " 178,\n",
       " 180,\n",
       " 182,\n",
       " 184,\n",
       " 186,\n",
       " 188,\n",
       " 190,\n",
       " 192,\n",
       " 194,\n",
       " 196,\n",
       " 198,\n",
       " 200,\n",
       " 202,\n",
       " 204,\n",
       " 206,\n",
       " 208,\n",
       " 210,\n",
       " 212,\n",
       " 214,\n",
       " 216,\n",
       " 218,\n",
       " 220,\n",
       " 222,\n",
       " 224,\n",
       " 226,\n",
       " 228,\n",
       " 230,\n",
       " 232,\n",
       " 234,\n",
       " 236,\n",
       " 238,\n",
       " 240,\n",
       " 242,\n",
       " 244,\n",
       " 246,\n",
       " 248,\n",
       " 250,\n",
       " 252,\n",
       " 254,\n",
       " 256,\n",
       " 258,\n",
       " 260,\n",
       " 262,\n",
       " 264,\n",
       " 266,\n",
       " 268,\n",
       " 270,\n",
       " 272,\n",
       " 274,\n",
       " 276,\n",
       " 278,\n",
       " 280,\n",
       " 282,\n",
       " 284,\n",
       " 286,\n",
       " 288,\n",
       " 290,\n",
       " 292,\n",
       " 294,\n",
       " 296,\n",
       " 298,\n",
       " 300,\n",
       " 302,\n",
       " 304,\n",
       " 306,\n",
       " 308,\n",
       " 310,\n",
       " 312,\n",
       " 314,\n",
       " 316,\n",
       " 318,\n",
       " 320,\n",
       " 322,\n",
       " 324,\n",
       " 326,\n",
       " 328,\n",
       " 330,\n",
       " 332,\n",
       " 334,\n",
       " 336,\n",
       " 338,\n",
       " 340,\n",
       " 342,\n",
       " 344,\n",
       " 346,\n",
       " 348,\n",
       " 350,\n",
       " 352,\n",
       " 354,\n",
       " 356,\n",
       " 358,\n",
       " 360,\n",
       " 362,\n",
       " 364,\n",
       " 366,\n",
       " 368,\n",
       " 370,\n",
       " 372,\n",
       " 374,\n",
       " 376,\n",
       " 378,\n",
       " 380,\n",
       " 382,\n",
       " 384,\n",
       " 386,\n",
       " 388,\n",
       " 390,\n",
       " 392,\n",
       " 394,\n",
       " 396,\n",
       " 398,\n",
       " 400,\n",
       " 402,\n",
       " 404,\n",
       " 406,\n",
       " 408,\n",
       " 410,\n",
       " 412,\n",
       " 414,\n",
       " 416,\n",
       " 418,\n",
       " 420,\n",
       " 422,\n",
       " 424,\n",
       " 426,\n",
       " 428,\n",
       " 430,\n",
       " 432,\n",
       " 434,\n",
       " 436,\n",
       " 438,\n",
       " 440,\n",
       " 442,\n",
       " 444,\n",
       " 446,\n",
       " 448,\n",
       " 450,\n",
       " 452,\n",
       " 454,\n",
       " 456,\n",
       " 458,\n",
       " 460,\n",
       " 462,\n",
       " 464,\n",
       " 466,\n",
       " 468,\n",
       " 470,\n",
       " 472,\n",
       " 474,\n",
       " 476,\n",
       " 478,\n",
       " 480,\n",
       " 482,\n",
       " 484,\n",
       " 486,\n",
       " 488,\n",
       " 490,\n",
       " 492,\n",
       " 494,\n",
       " 496,\n",
       " 498,\n",
       " 500,\n",
       " 502,\n",
       " 504,\n",
       " 506,\n",
       " 508,\n",
       " 510,\n",
       " 512,\n",
       " 514,\n",
       " 516,\n",
       " 518,\n",
       " 520,\n",
       " 522,\n",
       " 524,\n",
       " 526,\n",
       " 528,\n",
       " 530,\n",
       " 532,\n",
       " 534,\n",
       " 536,\n",
       " 538,\n",
       " 540,\n",
       " 542,\n",
       " 544,\n",
       " 546,\n",
       " 548,\n",
       " 550,\n",
       " 552,\n",
       " 554,\n",
       " 556,\n",
       " 558,\n",
       " 560,\n",
       " 562,\n",
       " 564,\n",
       " 566,\n",
       " 568,\n",
       " 570,\n",
       " 572,\n",
       " 574,\n",
       " 576,\n",
       " 578,\n",
       " 580,\n",
       " 582,\n",
       " 584,\n",
       " 586,\n",
       " 588,\n",
       " 590,\n",
       " 592,\n",
       " 594,\n",
       " 596,\n",
       " 598,\n",
       " 600,\n",
       " 602,\n",
       " 604,\n",
       " 606,\n",
       " 608,\n",
       " 610,\n",
       " 612,\n",
       " 614,\n",
       " 616,\n",
       " 618,\n",
       " 620,\n",
       " 622,\n",
       " 624,\n",
       " 626,\n",
       " 628,\n",
       " 630,\n",
       " 632,\n",
       " 634,\n",
       " 636,\n",
       " 638,\n",
       " 640,\n",
       " 642,\n",
       " 644,\n",
       " 646,\n",
       " 648,\n",
       " 650,\n",
       " 652,\n",
       " 654,\n",
       " 656,\n",
       " 658,\n",
       " 660,\n",
       " 662,\n",
       " 664,\n",
       " 666,\n",
       " 668,\n",
       " 670,\n",
       " 672,\n",
       " 674,\n",
       " 676,\n",
       " 678,\n",
       " 680,\n",
       " 682,\n",
       " 684,\n",
       " 686,\n",
       " 688,\n",
       " 690,\n",
       " 692,\n",
       " 694,\n",
       " 696,\n",
       " 698,\n",
       " 700,\n",
       " 702,\n",
       " 704,\n",
       " 706,\n",
       " 708,\n",
       " 710,\n",
       " 712,\n",
       " 714,\n",
       " 716,\n",
       " 718,\n",
       " 720,\n",
       " 722,\n",
       " 724,\n",
       " 726,\n",
       " 728,\n",
       " 730,\n",
       " 732,\n",
       " 734,\n",
       " 736,\n",
       " 738,\n",
       " 740,\n",
       " 742,\n",
       " 744,\n",
       " 746,\n",
       " 748,\n",
       " 750,\n",
       " 752,\n",
       " 754,\n",
       " 756,\n",
       " 758,\n",
       " 760,\n",
       " 762,\n",
       " 764,\n",
       " 766,\n",
       " 768,\n",
       " 770,\n",
       " 772,\n",
       " 774,\n",
       " 776,\n",
       " 778,\n",
       " 780,\n",
       " 782,\n",
       " 784,\n",
       " 786,\n",
       " 788,\n",
       " 790,\n",
       " 792,\n",
       " 794,\n",
       " 796,\n",
       " 798,\n",
       " 800,\n",
       " 802,\n",
       " 804,\n",
       " 806,\n",
       " 808,\n",
       " 810,\n",
       " 812,\n",
       " 814,\n",
       " 816,\n",
       " 818,\n",
       " 820,\n",
       " 822,\n",
       " 824,\n",
       " 826,\n",
       " 828,\n",
       " 830,\n",
       " 832,\n",
       " 834,\n",
       " 836,\n",
       " 838,\n",
       " 840,\n",
       " 842,\n",
       " 844,\n",
       " 846,\n",
       " 848,\n",
       " 850,\n",
       " 852,\n",
       " 854,\n",
       " 856,\n",
       " 858,\n",
       " 860,\n",
       " 862,\n",
       " 864,\n",
       " 866,\n",
       " 868,\n",
       " 870,\n",
       " 872,\n",
       " 874,\n",
       " 876,\n",
       " 878,\n",
       " 880,\n",
       " 882,\n",
       " 884,\n",
       " 886,\n",
       " 888,\n",
       " 890,\n",
       " 892,\n",
       " 894,\n",
       " 896,\n",
       " 898,\n",
       " 900,\n",
       " 902,\n",
       " 904,\n",
       " 906,\n",
       " 908,\n",
       " 910,\n",
       " 912,\n",
       " 914,\n",
       " 916,\n",
       " 918,\n",
       " 920,\n",
       " 922,\n",
       " 924,\n",
       " 926,\n",
       " 928,\n",
       " 930,\n",
       " 932,\n",
       " 934,\n",
       " 936,\n",
       " 938,\n",
       " 940,\n",
       " 942,\n",
       " 944,\n",
       " 946,\n",
       " 948,\n",
       " 950,\n",
       " 952,\n",
       " 954,\n",
       " 956,\n",
       " 958,\n",
       " 960,\n",
       " 962,\n",
       " 964,\n",
       " 966,\n",
       " 968,\n",
       " 970,\n",
       " 972,\n",
       " 974,\n",
       " 976,\n",
       " 978,\n",
       " 980,\n",
       " 982,\n",
       " 984,\n",
       " 986,\n",
       " 988,\n",
       " 990,\n",
       " 992,\n",
       " 994,\n",
       " 996,\n",
       " 998,\n",
       " 1000,\n",
       " 1002,\n",
       " 1004,\n",
       " 1006,\n",
       " 1008,\n",
       " 1010,\n",
       " 1012,\n",
       " 1014,\n",
       " 1016,\n",
       " 1018,\n",
       " 1020,\n",
       " 1022,\n",
       " 1024,\n",
       " 1026,\n",
       " 1028,\n",
       " 1030,\n",
       " 1032,\n",
       " 1034,\n",
       " 1036,\n",
       " 1038,\n",
       " 1040,\n",
       " 1042,\n",
       " 1044,\n",
       " 1046,\n",
       " 1048,\n",
       " 1050,\n",
       " 1052,\n",
       " 1054,\n",
       " 1056,\n",
       " 1058,\n",
       " 1060,\n",
       " 1062,\n",
       " 1064,\n",
       " 1066,\n",
       " 1068,\n",
       " 1070,\n",
       " 1072,\n",
       " 1074,\n",
       " 1076,\n",
       " 1078,\n",
       " 1080,\n",
       " 1082,\n",
       " 1084,\n",
       " 1086,\n",
       " 1088,\n",
       " 1090,\n",
       " 1092,\n",
       " 1094,\n",
       " 1096,\n",
       " 1098,\n",
       " 1100,\n",
       " 1102,\n",
       " 1104,\n",
       " 1106,\n",
       " 1108,\n",
       " 1110,\n",
       " 1112,\n",
       " 1114,\n",
       " 1116,\n",
       " 1118,\n",
       " 1120,\n",
       " 1122,\n",
       " 1124,\n",
       " 1126,\n",
       " 1128,\n",
       " 1130,\n",
       " 1132,\n",
       " 1134,\n",
       " 1136,\n",
       " 1138,\n",
       " 1140,\n",
       " 1142,\n",
       " 1144,\n",
       " 1146,\n",
       " 1148,\n",
       " 1150,\n",
       " 1152,\n",
       " 1154,\n",
       " 1156,\n",
       " 1158,\n",
       " 1160,\n",
       " 1162,\n",
       " 1164,\n",
       " 1166,\n",
       " 1168,\n",
       " 1170,\n",
       " 1172,\n",
       " 1174,\n",
       " 1176,\n",
       " 1178,\n",
       " 1180,\n",
       " 1182,\n",
       " 1184,\n",
       " 1186,\n",
       " 1188,\n",
       " 1190,\n",
       " 1192,\n",
       " 1194,\n",
       " 1196,\n",
       " 1198,\n",
       " 1200,\n",
       " 1202,\n",
       " 1204,\n",
       " 1206,\n",
       " 1208,\n",
       " 1210,\n",
       " 1212,\n",
       " 1214,\n",
       " 1216,\n",
       " 1218,\n",
       " 1220,\n",
       " 1222,\n",
       " 1224,\n",
       " 1226,\n",
       " 1228,\n",
       " 1230,\n",
       " 1232,\n",
       " 1234,\n",
       " 1236,\n",
       " 1238,\n",
       " 1240,\n",
       " 1242,\n",
       " 1244,\n",
       " 1246,\n",
       " 1248,\n",
       " 1250,\n",
       " 1252,\n",
       " 1254,\n",
       " 1256,\n",
       " 1258,\n",
       " 1260,\n",
       " 1262,\n",
       " 1264,\n",
       " 1266,\n",
       " 1268,\n",
       " 1270,\n",
       " 1272,\n",
       " 1274,\n",
       " 1276,\n",
       " 1278,\n",
       " 1280,\n",
       " 1282,\n",
       " 1284,\n",
       " 1286,\n",
       " 1288,\n",
       " 1290,\n",
       " 1292,\n",
       " 1294,\n",
       " 1296,\n",
       " 1298,\n",
       " 1300,\n",
       " 1302,\n",
       " 1304,\n",
       " 1306,\n",
       " 1308,\n",
       " 1310,\n",
       " 1312,\n",
       " 1314,\n",
       " 1316,\n",
       " 1318,\n",
       " 1320,\n",
       " 1322,\n",
       " 1324,\n",
       " 1326,\n",
       " 1328,\n",
       " 1330,\n",
       " 1332,\n",
       " 1334,\n",
       " 1336,\n",
       " 1338,\n",
       " 1340,\n",
       " 1342,\n",
       " 1344,\n",
       " 1346,\n",
       " 1348,\n",
       " 1350,\n",
       " 1352,\n",
       " 1354,\n",
       " 1356,\n",
       " 1358,\n",
       " 1360,\n",
       " 1362,\n",
       " 1364,\n",
       " 1366,\n",
       " 1368,\n",
       " 1370,\n",
       " 1372,\n",
       " 1374,\n",
       " 1376,\n",
       " 1378,\n",
       " 1380,\n",
       " 1382,\n",
       " 1384,\n",
       " 1386,\n",
       " 1388,\n",
       " 1390,\n",
       " 1392,\n",
       " 1394,\n",
       " 1396,\n",
       " 1398,\n",
       " 1400,\n",
       " 1402,\n",
       " 1404,\n",
       " 1406,\n",
       " 1408,\n",
       " 1410,\n",
       " 1412,\n",
       " 1414,\n",
       " 1416,\n",
       " 1418,\n",
       " 1420,\n",
       " 1422,\n",
       " 1424,\n",
       " 1426,\n",
       " 1428,\n",
       " 1430,\n",
       " 1432,\n",
       " 1434,\n",
       " 1436,\n",
       " 1438,\n",
       " 1440,\n",
       " 1442,\n",
       " 1444,\n",
       " 1446,\n",
       " 1448,\n",
       " 1450,\n",
       " 1452,\n",
       " 1454,\n",
       " 1456,\n",
       " 1458,\n",
       " 1460,\n",
       " 1462,\n",
       " 1464,\n",
       " 1466,\n",
       " 1468,\n",
       " 1470,\n",
       " 1472,\n",
       " 1474,\n",
       " 1476,\n",
       " 1478,\n",
       " 1480,\n",
       " 1482,\n",
       " 1484,\n",
       " 1486,\n",
       " 1488,\n",
       " 1490,\n",
       " 1492,\n",
       " 1494,\n",
       " 1496,\n",
       " 1498,\n",
       " 1500,\n",
       " 1502,\n",
       " 1504,\n",
       " 1506,\n",
       " 1508,\n",
       " 1510,\n",
       " 1512,\n",
       " 1514,\n",
       " 1516,\n",
       " 1518,\n",
       " 1520,\n",
       " 1522,\n",
       " 1524,\n",
       " 1526,\n",
       " 1528,\n",
       " 1530,\n",
       " 1532,\n",
       " 1534,\n",
       " 1536,\n",
       " 1538,\n",
       " 1540,\n",
       " 1542,\n",
       " 1544,\n",
       " 1546,\n",
       " 1548,\n",
       " 1550,\n",
       " 1552,\n",
       " 1554,\n",
       " 1556,\n",
       " 1558,\n",
       " 1560,\n",
       " 1562,\n",
       " 1564,\n",
       " 1566,\n",
       " 1568,\n",
       " 1570,\n",
       " 1572,\n",
       " 1574,\n",
       " 1576,\n",
       " 1578,\n",
       " 1580,\n",
       " 1582,\n",
       " 1584,\n",
       " 1586,\n",
       " 1588,\n",
       " 1590,\n",
       " 1592,\n",
       " 1594,\n",
       " 1596,\n",
       " 1598,\n",
       " 1600,\n",
       " 1602,\n",
       " 1604,\n",
       " 1606,\n",
       " 1608,\n",
       " 1610,\n",
       " 1612,\n",
       " 1614,\n",
       " 1616,\n",
       " 1618,\n",
       " 1620,\n",
       " 1622,\n",
       " 1624,\n",
       " 1626,\n",
       " 1628,\n",
       " 1630,\n",
       " 1632,\n",
       " 1634,\n",
       " 1636,\n",
       " 1638,\n",
       " 1640,\n",
       " 1642,\n",
       " 1644,\n",
       " 1646,\n",
       " 1648,\n",
       " 1650,\n",
       " 1652,\n",
       " 1654,\n",
       " 1656,\n",
       " 1658,\n",
       " 1660,\n",
       " 1662,\n",
       " 1664,\n",
       " 1666,\n",
       " 1668,\n",
       " 1670,\n",
       " 1672,\n",
       " 1674,\n",
       " 1676,\n",
       " 1678,\n",
       " 1680,\n",
       " 1682,\n",
       " 1684,\n",
       " 1686,\n",
       " 1688,\n",
       " 1690,\n",
       " 1692,\n",
       " 1694,\n",
       " 1696,\n",
       " 1698,\n",
       " 1700,\n",
       " 1702,\n",
       " 1704,\n",
       " 1706,\n",
       " 1708,\n",
       " 1710,\n",
       " 1712,\n",
       " 1714,\n",
       " 1716,\n",
       " 1718,\n",
       " 1720,\n",
       " 1722,\n",
       " 1724,\n",
       " 1726,\n",
       " 1728,\n",
       " 1730,\n",
       " 1732,\n",
       " 1734,\n",
       " 1736,\n",
       " 1738,\n",
       " 1740,\n",
       " 1742,\n",
       " 1744,\n",
       " 1746,\n",
       " 1748,\n",
       " 1750,\n",
       " 1752,\n",
       " 1754,\n",
       " 1756,\n",
       " 1758,\n",
       " 1760,\n",
       " 1762,\n",
       " 1764,\n",
       " 1766,\n",
       " 1768,\n",
       " 1770,\n",
       " 1772,\n",
       " 1774,\n",
       " 1776,\n",
       " 1778,\n",
       " 1780,\n",
       " 1782,\n",
       " 1784,\n",
       " 1786,\n",
       " 1788,\n",
       " 1790,\n",
       " 1792,\n",
       " 1794,\n",
       " 1796,\n",
       " 1798,\n",
       " 1800,\n",
       " 1802,\n",
       " 1804,\n",
       " 1806,\n",
       " 1808,\n",
       " 1810,\n",
       " 1812,\n",
       " 1814,\n",
       " 1816,\n",
       " 1818,\n",
       " 1820,\n",
       " 1822,\n",
       " 1824,\n",
       " 1826,\n",
       " 1828,\n",
       " 1830,\n",
       " 1832,\n",
       " 1834,\n",
       " 1836,\n",
       " 1838,\n",
       " 1840,\n",
       " 1842,\n",
       " 1844,\n",
       " 1846,\n",
       " 1848,\n",
       " 1850,\n",
       " 1852,\n",
       " 1854,\n",
       " 1856,\n",
       " 1858,\n",
       " 1860,\n",
       " 1862,\n",
       " 1864,\n",
       " 1866,\n",
       " 1868,\n",
       " 1870,\n",
       " 1872,\n",
       " 1874,\n",
       " 1876,\n",
       " 1878,\n",
       " 1880,\n",
       " 1882,\n",
       " 1884,\n",
       " 1886,\n",
       " 1888,\n",
       " 1890,\n",
       " 1892,\n",
       " 1894,\n",
       " 1896,\n",
       " 1898,\n",
       " 1900,\n",
       " 1902,\n",
       " 1904,\n",
       " 1906,\n",
       " 1908,\n",
       " 1910,\n",
       " 1912,\n",
       " 1914,\n",
       " 1916,\n",
       " 1918,\n",
       " 1920,\n",
       " 1922,\n",
       " 1924,\n",
       " 1926,\n",
       " 1928,\n",
       " 1930,\n",
       " 1932,\n",
       " 1934,\n",
       " 1936,\n",
       " 1938,\n",
       " 1940,\n",
       " 1942,\n",
       " 1944,\n",
       " 1946,\n",
       " 1948,\n",
       " 1950,\n",
       " 1952,\n",
       " 1954,\n",
       " 1956,\n",
       " 1958,\n",
       " 1960,\n",
       " 1962,\n",
       " 1964,\n",
       " 1966,\n",
       " 1968,\n",
       " 1970,\n",
       " 1972,\n",
       " 1974,\n",
       " 1976,\n",
       " 1978,\n",
       " 1980,\n",
       " 1982,\n",
       " 1984,\n",
       " 1986,\n",
       " 1988,\n",
       " 1990,\n",
       " 1992,\n",
       " 1994,\n",
       " 1996,\n",
       " 1998,\n",
       " ...]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Next, let's create another function that uses NumPy (or equivalent) to do the same. To try it out, allocate two arrays (e.g. using <span style=\"background-color: #ccfff2\"> np.array</span> in NumPy) and add the arrays together using your function. Don't use loops, instead, find out how to add the two arrays directly. What do you notice in comparison to the previous function?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import numpy as np\n",
    "np_A = np_B = np.arange(0, int(1e7-1))\n",
    "def add_with_np(A,B):\n",
    "    C = np.add(A,B)\n",
    "    return C\n",
    "\n",
    "add_with_np(np_A,np_B)\n",
    "\n",
    "# I can notice that it's really faster (1.6s using the for vs 0.1 using numpy on my machine)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([       0,        2,        4, ..., 19999992, 19999994, 19999996])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Array manipulation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"background-color: #ccfff2\"> *Note: for the following exercises, only use NumPy or equivalent functions. Don't use any loops.* </span>\n",
    "1. Create the following array:\n",
    "\n",
    "*[hint: <span style=\"background-color: #ccfff2\"> np.reshape</span>]*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
    "#        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
    "#        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
    "#        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
    "#        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
    "#        [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
    "#        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
    "#        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
    "#        [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
    "#        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "np.reshape(np.arange(0,100),(10,10))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "       [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
       "       [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
       "       [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
       "       [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
       "       [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Create the following array:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# array([[0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "np.resize([0.,1.], (10,10))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Create the following array (D):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# array([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "D = np.ones((10,10), float)\n",
    "np.fill_diagonal(D, 0.)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Create the following array (E):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "E = np.fliplr(D)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Call the last two matrices <span style=\"background-color: #ccfff2\">D</span> and <span style=\"background-color: #ccfff2\">E</span>, respectively. Show that the determinant of their product (matrix multiplication) is the same as the product of their determinants. That is calculate both <span style=\"background-color: #ccfff2\">det(DE)</span> and <span style=\"background-color: #ccfff2\">det(D) * det(E)</span>, and show that they are the same. Why does this hold in this instance? Does it hold in general? The product of the determinants (or the determinant of the product) should be -81."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "f_det = int(np.linalg.det(np.matmul(D,E)))\n",
    "s_det = int(np.linalg.det(D)*np.linalg.det(E))\n",
    "print(f_det == s_det)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This holds in this instance for the Binet Theorem. In fact, the Binet Theorem states that:\n",
    "\n",
    "Let ```A``` and ```B``` be two **square matrices** (i.e. with the number of columns equal to the number of rows), **with the same number of rows**, then the determinant of the product between A and B is equal to the product of the determinant of A and the determinant of B.\n",
    "\n",
    "In this case the hypotesis is true, since both are square matrices and they have the same number of rows (two 10x10 matrices), so that applies."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 Slicing\n",
    "\n",
    "Array slicing is a powerful way to extract data from an array. Let's practice array slicing with the following exercises!\n",
    "\n",
    "1. Load the [Boston housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html). The data should be a matrix of shape <span style=\"background-color: #ccfff2\">(506, 13)</span>, that is 506 rows and 13 columns. Use the <span style=\"background-color: #ccfff2\">.shape</span> attribute of NumPy arrays to verify this. Here's a [description of the fields](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "boston = sklearn.datasets.load_boston()\n",
    "print(boston.data.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(506, 13)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Select rows where the Crime feature <span style=\"background-color: #ccfff2\">(CRIM)</span> is higher than 1. The first few row numbers should be <span style=\"background-color: #ccfff2\">16, 20, 22</span> (zero-indexed). How many are there? *[hint: <span style=\"background-color: #ccfff2\">np.where</span>]*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "idx, = np.where(boston.feature_names == 'CRIM')[0]\n",
    "rows = np.where(boston.data[:,idx]>1)\n",
    "crim_higher_1 = boston.data[rows]\n",
    "print(len(rows[0])) # 174"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "174\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Select the rows where the pupil-to-teach ratio <span style=\"background-color: #ccfff2\">(PTRATIO)</span> is between 16% and 18% (exclusive). There should be **100** of these."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "idx, = np.where(boston.feature_names == 'PTRATIO')[0]\n",
    "rows = np.where((boston.data[:,idx]>16) & (boston.data[:,idx]<18))\n",
    "ptratio_between = boston.data[rows]\n",
    "print(len(rows[0]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Find the mean nitric oxides concentration <span style=\"background-color: #ccfff2\">(NOX)</span> for homes whose median price is more than 25000 USD (the target variable). It should be around **0.492**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "idx, = np.where(boston.feature_names == 'NOX')[0]\n",
    "rows = np.where(boston.target>25)\n",
    "noxes = boston.data[rows]\n",
    "print(np.mean(noxes[:,idx]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.4921201612903226\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise 2 | Working with text data\n",
    "\n",
    "Next, let's look into some text data. We will be looking into Amazon reviews, and the steps needed to transform a raw dataset into a format more suitable for prediction tasks.\n",
    "\n",
    "1. Download the automotive 5-core dataset from [here](http://jmcauley.ucsd.edu/data/amazon/). Next, you can extract the data in <span style=\"background-color: #ccfff2\">JSON</span> format. You can also download one of the bigger ones, if you are feeling ambitious. Open the JSON file. Access the <span style=\"background-color: #ccfff2\">reviewText</span> field, which contains the unstructured review text written by the user. \n",
    "\n",
    "For instance the first review reads as follows: \n",
    "\n",
    "*'I needed a set of jumper cables for my new car and these had good reviews and were at a good price.  They have been used a few times already and do what they are supposed to - no complaints there.What I will say is that 12 feet really isn't an ideal length.  Sure, if you pull up front bumper to front bumper they are plenty long, but a lot of times you will be beside another car or can't get really close.  Because of this, I would recommend something a little longer than 12'.Great brand - get 16' version though.'*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "automotive = pd.read_json(r'./Automotive_5.json', lines=True)\n",
    "\n",
    "reviewTexts = automotive['reviewText']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Next, let's follow some steps to normalize the text data.\n",
    "\n",
    "When dealing with natural language, it is important to notice that while, for example, the words \"Copper\" and \"copper\" are represented by two different strings, they have the same meaning. When applying statistical methods on this data, it is useful to ensure that words with the same meaning are represented by the same string.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Downcasing</span>: Let's first downcase the contents of the <span style=\"background-color: #ccfff2\">reviewText</span> field.\n",
    "\n",
    "Now the first review should be:\n",
    "\n",
    "*'i needed a set of jumper cables for my new car and these had good reviews and were at a good price.  they have been used a few times already and do what they are supposed to - no complaints there.what i will say is that 12 feet really isn't an ideal length.  sure, if you pull up front bumper to front bumper they are plenty long, but a lot of times you will be beside another car or can't get really close.  because of this, i would recommend something a little longer than 12'.great brand - get 16' version though.'*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "automotive['reviewText'] = automotive['reviewText'].str.lower()\n",
    "#print(automotive['reviewText'].head(3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    i needed a set of jumper cables for my new car...\n",
      "1    these long cables work fine for my truck, but ...\n",
      "2    can't comment much on these since they have no...\n",
      "Name: reviewText, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Let's continue with punctuation and stop word removal. Stop words are words like \"and\", \"the\", etc. They are usually very common words that have little to do with the actual content matter. There's plenty openly available lists of stop words for almost any (natural) language.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Punctuation and stop-word removal</span>: Let's now remove all punctuation, as well as the stop words. You can find a stop word list for English, e.g. [here](http://xpo6.com/download-stop-word-list/) *(use the link for CSV download of english stop words)*.\n",
    "\n",
    "First review at this point reads as: \n",
    "\n",
    "*'needed set jumper cables new car good reviews good price used few times already supposed complaints therewhat 12 feet really isnt ideal length sure pull up front bumper front bumper plenty long lot times beside another car cant really close recommend something little longer 12great brand 16 version though'*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Remove puntuaction\n",
    "import string\n",
    "automotive['reviewText'] = automotive['reviewText'].str.replace('[{}]'.format(string.punctuation), '',regex=True)\n",
    "\n",
    "# Remove stopwords\n",
    "stopWords = pd.read_csv('./stop-word-list.csv', delimiter=', ', header=None, index_col=False, engine='python').to_numpy()[0]\n",
    "automotive['reviewText'] = automotive['reviewText'].apply(lambda x: ' '.join([k for k in x.split() if k not in stopWords]))\n",
    "\n",
    "#print(automotive['reviewText'].head(3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    needed set jumper cables new car good reviews ...\n",
      "1    long cables work fine truck quality seems litt...\n",
      "2    cant comment much used come back update review...\n",
      "Name: reviewText, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Let's continue with stemming. For example, while the words \"swims\" and \"swim\" are different strings, they both refer to swimming. [Stemming](https://en.wikipedia.org/wiki/Stemming) refers to the process of mapping words in inflected form to their base form, for instance: swims -> swim.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Stemming</span>: Apply a stemmer on the paragraphs, so that inflected forms are mapped to the base form. For example, for Python the popular natural language toolkit [nltk](http://www.nltk.org/howto/stem.html) has an easy to use stemmer. In case you are using R, you can try the [Snowball stemmer](https://www.rdocumentation.org/packages/corpus/versions/0.10.2/topics/stem_snowball).\n",
    "\n",
    "Finally, after stemming: \n",
    "\n",
    "*'need set jumper cabl new car good review good price use few time alreadi suppos complaint therewhat 12 feet realli isnt ideal length sure pull up front bumper front bumper plenti long lot time besid anoth car cant realli close recommend someth littl longer 12great brand 16 version though'*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "automotive['reviewText'] = automotive['reviewText'].apply(lambda x: ' '.join([stemmer.stem(y) for y in x.split()]))\n",
    "#print(automotive['reviewText'].head(3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    need set jumper cabl new car good review good ...\n",
      "1    long cabl work fine truck qualiti seem littl s...\n",
      "2    cant comment much use come back updat review f...\n",
      "Name: reviewText, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Finally, filter the data by selecting reviews where the field <span style=\"background-color: #ccfff2\">overall</span> is 4 or 5, and store the review texts in file <span style=\"background-color: #ccfff2\">pos.txt</span>. Similarly, select reviews with rating 1 or 2 and store the reviews in file <span style=\"background-color: #ccfff2\">neg.txt</span>. Ignore the reviews with overall rating 3. Each line in the two files should contain exactly one preprocessed review text without the rating."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "pos, neg = (automotive.loc[automotive['overall']>=4])['reviewText'], (automotive.loc[automotive['overall']<=2])['reviewText']\n",
    "np.savetxt(r'./pos.txt', pos.values, fmt='%s')\n",
    "np.savetxt(r'./neg.txt', neg.values, fmt='%s')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Having created two collections of positive and negative reviews, respectively, you may wish to take a quick look to see how the review texts differ between them (positive vs negative). We will be using this data later to experiment with machine learning methods.\n",
    "\n",
    "**Remember to submit your code on Moodle. You can return this Jupyter notebook (.ipynb) or .py, .R, etc depending on your programming preferences. No need to submit the text files.**"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "d2152fd7f0bbc62aa1baff8c990435d1e2c7175d001561303988032604c11a48"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}